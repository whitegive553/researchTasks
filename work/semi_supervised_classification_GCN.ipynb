{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# semi-supervised learning on graph structure daata"
      ],
      "metadata": {
        "id": "xbZnKTaB9Vci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## technical terms    \n",
        "\n",
        "### Laplacian Matrix:\n",
        "degree matrix - adjacency matrix, show the degree of tied Strong and relation with other nodes.\n",
        "\n",
        "### Graph Laplacian Regularization:\n",
        "L_reg If X and Y is connected, then the output F(x) and F(Y) should be similar, higher different change between the output would cause higher loss. L = L_0 + L_reg\n",
        "\n",
        "### forward model:\n",
        "the model used in forward propagation. Two layer Two activation function: relu bring non linear relationship. Softmax used in classification last layer, transit the output to be an probability density function. and the total probability is 1.\n",
        "\n",
        "### baseline:\n",
        "already exsist approach or model, to validate whether this model is better\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jATvHMEU9rcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Layer wise propagation: add self-connection and change of degree matrix comes from renormalization trick, to deal with numerical instabilities and exploding gradients."
      ],
      "metadata": {
        "id": "rLwAzC8NTVrr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# approximate convolutions on graph\n",
        "We use spectral convolution $g_\\theta\\ast x $ by set filter $g_\\theta$ as a function of $\\land$, it's being set up by $U^Tx$ get the value of projection on each eigonvector of Laplacian Matrix L, which contain the structure of the graph. Laplacian $\\land$ actually represent the eigonvalue, where it shows the information of the x really contain after it project on the eigonvectors. what filter does is filter the actual magnitude on the specific eigonvector direction we want. higher value of g_ii represent change faster at that direction. After these, we project the selected, changed vector back to the original space."
      ],
      "metadata": {
        "id": "JrpF3Dw3Mfbz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# summary\n",
        "## Using Spectral approach working on semi-supervised learning. Get advantage from layer wise propagation to achieve high calculation efficency. Decrease complexcity from O(N^3) to O(|E|) linearity with number of edge."
      ],
      "metadata": {
        "id": "SbHn0FJr9rBH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## question\n",
        "$\n",
        "z \\approx \\theta \\left( I_N + D^{-\\frac{1}{2}} A D^{-\\frac{1}{2}} \\right) x$\n",
        " why this can cause exploding gradients    \n",
        "\n",
        " $U g_\\theta U^\\top x$ why this is O(N^2)\n"
      ],
      "metadata": {
        "id": "BIqbv9sWW2lj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pbY0OW4n9qXp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}